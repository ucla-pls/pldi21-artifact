{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook, which contains the results of running our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "def pretty(ax):\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    for spine in [ax.spines['left'], ax.spines['bottom'], ax.spines[\"right\"], ax.spines['top']]:\n",
    "        spine.set_position((\"outward\", 5))\n",
    "        spine.set_color(\"gray\")\n",
    "        \n",
    "    for axis in [ax.yaxis, ax.xaxis]:\n",
    "        for x in axis.get_major_ticks():\n",
    "            x.label1.set_color(\"gray\")\n",
    "            x.label2.set_color(\"gray\")\n",
    "            x.tick1line.set_color(\"gray\")\n",
    "            x.tick2line.set_color(\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full\n",
    "\n",
    "This section covers the evaluation where we preserve the full bug. We start by loading the the data and indexing by `name`, `predicate`, and `strategy`. The data have been computed and put in `results/result.csv` by our evalutation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"result/full/result.csv\").set_index([\"name\", \"predicate\",\"strategy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A single line of our data looks like this, we store the follwing data: \n",
    "\n",
    "*  `bugs` which contain the number of lines in the cleaned up bug-report\n",
    "\n",
    "*  `initial-scc` and `scc` contain the number of strongly connected components before and after reduction,\n",
    "\n",
    "*  `initial-classes` and `classes` contain the number of classes before and after reduction,\n",
    "\n",
    "*  `initial-bytes` and `bytes` contain the number of bytes before and after reduction,\n",
    "\n",
    "*  `iters` which contain the number of invocations of the predicate, \n",
    "\n",
    "*  `searches` the number of binary searches made by algorithm\n",
    "\n",
    "*  `time` which records the time to reach the final successfull solution,\n",
    "\n",
    "*  `status` which records whether the reduction completed correctly,\n",
    "\n",
    "*  `verify` which records information about if bug is preserved.\n",
    "\n",
    "Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\"url0067cdd33d_goldolphin_Mi\", \"cfr\", \"logic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10,3), sharey=True)\n",
    "\n",
    "bugs = results[\"bugs\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_bytes = results[\"initial-bytes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_classes = results[\"initial-classes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_variables = results[\"initial-scc\"].unstack(\"strategy\")[\"logic\"]\n",
    "\n",
    "number_of_benchmarks = len(bugs.index)\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Histogram of Classes\"\n",
    "    , \"data\": initial_classes\n",
    "    , \"xlabel\": \"Classes\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Bytes (in MB)\"\n",
    "    , \"data\": initial_bytes\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000000 :0.2f}'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.0f} KB'\n",
    "    , \"xlabel\": \"Bytes (in MB)\"\n",
    "    },\n",
    "#    { \"title\": \"Histogram of Variables\"\n",
    "#    , \"data\": initial_variables\n",
    "#    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.1f} k'\n",
    "#    , \"xlabel\": \"Variables\"\n",
    "#    },\n",
    "    { \"title\": \"Histogram of Bugs\"\n",
    "    , \"data\": bugs\n",
    "    , \"xlabel\": \"Bugs\"\n",
    "    , \"splits\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "axes[0].set_ylabel(\"Bencmarks\")\n",
    "for ax, diagram in zip(axes, diagrams):\n",
    "    #ax.set_title(diagram[\"title\"])\n",
    "    \n",
    "    \n",
    "    pretty(ax)\n",
    "    \n",
    "    data = diagram[\"data\"]\n",
    "    xlim = (data.min(), data.max())\n",
    "    splits = diagram.get(\"splits\",np.linspace(*xlim, 11).round(0))\n",
    "    \n",
    "    \n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xticks(splits[::2])\n",
    "    ax.set_xticks(splits, minor=True)\n",
    "    \n",
    "    \n",
    "    ylim = (0, number_of_benchmarks)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks(np.linspace(*ylim, 8).round(0))\n",
    "    if ax != axes[0]:\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        for x in ax.yaxis.get_major_ticks():\n",
    "            x.set_visible(False)\n",
    "    ax.set_xlabel(diagram[\"xlabel\"])\n",
    "   \n",
    "    blocks = ax.hist(diagram[\"data\"], splits, color=\"black\", rwidth=0.75)\n",
    "    \n",
    "    \n",
    "    xformat = diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(xformat))\n",
    "    #ax.xaxis.set_tick_params(rotation=70)\n",
    "    \n",
    "    gmean = stats.gmean(diagram[\"data\"])\n",
    "    v = ax.vlines(gmean, *ylim)\n",
    "    v.set_color(\"gray\")\n",
    "    v.set_linestyle(\":\")\n",
    "    \n",
    "    t = ax.text(gmean + xlim[1] * 0.05, ylim[1] * 0.94, \"GM \" + diagram.get(\"format\", xformat)(gmean, 0))\n",
    "    t.set_color(\"gray\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.18)\n",
    "fig.savefig(\"benchmarks.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing four startegies: \n",
    "\n",
    "- classes\n",
    "- logic+approx\n",
    "- logic+graph\n",
    "- logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = list(reversed([\"classes\", \"logic\"]))\n",
    "\n",
    "p = [\"#0a1058\", \"#ee4242\", \"#ff9135\", \"#9857ff\", \"#4cb2ff\"]\n",
    "\n",
    "\n",
    "colors = {\"classes\" : \"#5F99E7\", \n",
    "          \"logic\": \"#1956A7\",\n",
    "        }\n",
    "shade = {\"classes\" : \"#F6F1B0\",\n",
    "          \"logic\": \"#B0B6F6\"\n",
    "        }\n",
    "\n",
    "labels = { \"jreduce\": \"J-Reduce\"\n",
    "         , \"classes\": \"J-Reduce\"\n",
    "         , \"items+hdd\": \"HDD\"\n",
    "         , \"logic+ddmin\": \"ddmin+\"\n",
    "         , \"logic+approx\": \"binary+\"\n",
    "         , \"logic\": \"Our Reducer\"\n",
    "         }\n",
    "\n",
    "styles = { \"jreduce\": \":\"\n",
    "         , \"classes\": \"-.\"\n",
    "         , \"items+hdd\": \":\"\n",
    "         , \"logic+ddmin\": \"--\"\n",
    "         , \"logic+approx\": \"-.\"\n",
    "         , \"logic\": \"-\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sanity Checks\n",
    "\n",
    "Before we go on to evaluate the code we check that the system is working correctly. First we check that the status is \"success\". We find the following distribution of statuses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14,2))\n",
    "\n",
    "timeouts = (results.status == \"timeout\").groupby(\"strategy\").mean()\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "pretty(ax)\n",
    "x = ax.barh(\n",
    "        [labels[s] for s in strategies], \n",
    "        [timeouts[s] * 100 for s in strategies], \n",
    "        color=[colors[s] for s in strategies],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a list of all the experiments that failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10000000\n",
    "for i in results.index:\n",
    "    (b, p, x) = i\n",
    "    if x != \"classes\": continue\n",
    "    if results.classes.loc[(b, p, x)] < results.classes.loc[(b, p, \"logic\")]:\n",
    "        if results[\"initial-bytes\"][i] < m:\n",
    "            m = results[\"initial-bytes\"][i]\n",
    "            print('/'.join(i), results[\"initial-bytes\"][i], results.bytes[i], results.bytes[(b, p, \"logic\")])\n",
    "            print(results.loc[(b, p, \"logic\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our comparative reducetion results we will update the times of all timeout items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 3600\n",
    "full = results.copy()\n",
    "full.loc[full.status == \"timeout\", \"time\"] = TIMEOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first experiment we are going to look at comparative final size, and time. We use the geometric mean, so that we can compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = full[[\"time\", \"bytes\", \"classes\"]].groupby(\"strategy\").agg(stats.gmean).loc[strategies]\n",
    "r.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_diagram(full):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10,3.5), sharey=True)\n",
    "    \n",
    "    diagrams = [\n",
    "        { \"title\": \"Finished Programs over Time\"\n",
    "        , \"xformat\": lambda x, pos: f'{x:0.0f}'\n",
    "        , \"data\": lambda s: list(sorted(d for d in full[\"time\"].unstack(\"strategy\")[s] if d < TIMEOUT)) + [TIMEOUT]\n",
    "        , \"xlim\": (0, 3600)\n",
    "        , \"xlabel\": \"Time Spend (s)\"\n",
    "        , \"percent\": False\n",
    "        },        \n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x:0.0f}'\n",
    "        , \"data\": lambda s: sorted(full[\"iters\"].unstack(\"strategy\")[s])\n",
    "        , \"xlim\": (0, 1500)\n",
    "        , \"xlabel\": \"Invocations Made\"\n",
    "        },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"classes\"].unstack(\"strategy\")[s] / initial_classes)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Bytes)\"\n",
    "        },\n",
    "        \n",
    "        ]\n",
    "\n",
    "    for diagram, ax in zip(diagrams, axes.flatten()):\n",
    "        maxx, minx = 0, 1000000000\n",
    "        pretty(ax)\n",
    "       \n",
    "        strats = sorted(strategies, key=lambda s: np.mean(diagram[\"data\"](s)))\n",
    "        for s in strats:\n",
    "            data = diagram[\"data\"](s)\n",
    "            ax.plot(data, [i + 1 for i,_ in enumerate(data)], \n",
    "                    label=labels[s], \n",
    "                    linestyle=styles[s],\n",
    "                    color=colors[s])\n",
    "            maxx = max(maxx, max(data))\n",
    "            minx = min(minx, min(data))\n",
    "            \n",
    "        minx = max(1, minx)\n",
    "        \n",
    "\n",
    "        xlim = diagram.get(\"xlim\", (0, maxx))\n",
    "        ax.set_xlim(*xlim)\n",
    "        xtics = diagram.get(\"xticks\", np.linspace(*xlim, 7))\n",
    "        ax.set_xticks(xtics)\n",
    "        \n",
    "        ylim = 0, number_of_benchmarks\n",
    "        ax.set_yticks(np.linspace(*ylim, 7).round())\n",
    "        ax.set_yticks([], minor=True)\n",
    "        ax.set_ylim(*ylim)\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(\"Benchmarks\")\n",
    "        \n",
    "        \n",
    "        if diagram.get(\"percent\", False):\n",
    "            ax2 = ax.twinx()\n",
    "            pretty(ax2)\n",
    "            \n",
    "            yticks = [227, 200]\n",
    "            strats = sorted(strategies, key=lambda s: -len(diagram[\"data\"](s)))\n",
    "            ytickslabels = [f\"{(len(diagram['data'](s)) - 1) / number_of_benchmarks * 100:0.0f} %\" for s in strats]\n",
    "            ax2.set_yticks(yticks)\n",
    "            ax2.set_yticklabels(ytickslabels)\n",
    "            #ax2.set_ylabel(\"Completion Rate\")\n",
    "        \n",
    "        \n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')))\n",
    "        \n",
    "        v = ax.hlines(round(number_of_benchmarks/2),*xlim)\n",
    "        v.set_color(\"gray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "        #v = ax.hlines(54 ,*xlim)\n",
    "        #v.set_color(\"gray\")\n",
    "        #v.set_linestyle(\":\")\n",
    "                            \n",
    "        if ax == axes[1]:\n",
    "            #t = ax.text(xlim[1] * 0.45, 54 + 5, \"ONE BUG\")\n",
    "            #t.set_color(\"gray\")\n",
    "            t = axes[1].text(xlim[1] * 0.47, round(len(data)/2) + 5, \"MEDIAN\")\n",
    "            t.set_color(\"gray\")\n",
    "        \n",
    "        ax.set_xlabel(diagram[\"xlabel\"])    \n",
    "    \n",
    "    axes[2].legend(loc=\"lower right\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = draw_diagram(full)\n",
    "fig.savefig(\"timings.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[[\"time\", \"iters\"]].groupby(\"strategy\").agg(stats.gmean).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs are formatted like the previous article: In the top row we have number programs that complete before a certain time and iterations. In the bottom row we have the number of programs that have been reduced to a size below a certian number of bytes or classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.iters.unstack(\"strategy\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "iter_maxes = full.iters.unstack(\"strategy\").max()\n",
    "\n",
    "glob = Path(\"result/full/\").glob(\"url*/*\")\n",
    "idfCs = []\n",
    "idfBs = []\n",
    "tdfCs = []\n",
    "tdfBs = []\n",
    "j = 0 \n",
    "for b in glob:\n",
    "    if not b.name in {\"cfr\", \"procyon\", \"fernflower\"}: continue\n",
    "    j += 1\n",
    "    #if j > 10: break\n",
    "    try:\n",
    "        idfC = pd.DataFrame()\n",
    "        idfB = pd.DataFrame()\n",
    "        tdfC = pd.DataFrame()\n",
    "        tdfB = pd.DataFrame()\n",
    "        metrics = list(b.glob(\"*/workfolder/metrics.csv\"))\n",
    "        if not metrics: continue\n",
    "        for i in metrics:\n",
    "            strat, *_ = i.relative_to(b).parts\n",
    "            if strat == \"logic+single\": continue\n",
    "            # print(i)\n",
    "            m = pd.read_csv(i)\n",
    "            \n",
    "            m.time = m.time.floordiv(60) + 1\n",
    "            x = m[m.judgment == \"success\"]\\\n",
    "                .groupby(\"time\")[[\"classes\", \"bytes\"]]\\\n",
    "                .min()\\\n",
    "                .reindex(index=range(0, 61))\\\n",
    "                .expanding().min()\n",
    "        \n",
    "            tdfC = tdfC.assign(**{strat: x[\"classes\"].fillna(m.loc[0][\"classes\"])})\n",
    "            tdfB = tdfB.assign(**{strat: x[\"bytes\"].fillna(m.loc[0][\"bytes\"])})\n",
    "        \n",
    "            y = m[m.judgment == \"success\"]\\\n",
    "                .groupby(\"folder\")[[\"classes\", \"bytes\"]]\\\n",
    "                .min()\\\n",
    "                .reindex(index=range(0, int(iter_maxes.max())))\\\n",
    "                .expanding().min()\n",
    "            \n",
    "            idfC = idfC.assign(**{strat: y[\"classes\"].fillna(m.loc[0][\"classes\"])})\n",
    "            idfB = idfB.assign(**{strat: y[\"bytes\"].fillna(m.loc[0][\"bytes\"])})\n",
    "        \n",
    "        idfCs.append(idfC)\n",
    "        idfBs.append(idfB)\n",
    "        tdfCs.append(tdfC)\n",
    "        tdfBs.append(tdfB)\n",
    "    except TypeError: raise\n",
    "    except Exception as e :\n",
    "        print(\"WARNING\", type(e), e, i)\n",
    "        continue\n",
    "\n",
    "times = (tdfCs, tdfBs)\n",
    "iters = (idfCs, idfBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(times[1]).groupby(\"time\").quantile(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10,7))\n",
    "\n",
    "tbytes = pd.concat(times[1]).groupby(\"time\").agg(stats.gmean)\n",
    "\n",
    "classgroup = pd.concat(times[0]).groupby(\"time\")\n",
    "tclasses = classgroup.agg(stats.gmean)\n",
    "\n",
    "tclasses1 = classgroup.quantile(0.25)\n",
    "tclasses2 = classgroup.quantile(0.75)\n",
    "\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Mean Classes Left Over Time (s)\"\n",
    "    , \"data\":  tclasses\n",
    "    # , \"quantiles\": (tclasses1, tclasses2)\n",
    "    , \"format\": lambda x, pos: f\"{x:0.0f}\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Classes Left\"\n",
    "    , \"best\": min\n",
    "    },\n",
    "    { \"title\": \"Mean Bytes Left Over Time (s)\"\n",
    "    , \"data\":  tbytes\n",
    "    , \"format\": lambda x, pos: f\"{x / 1000:0.0f} KB\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Bytes Left\"\n",
    "    , \"best\": min\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Classes Over Time (s)\"\n",
    "    , \"data\":  tclasses.rdiv(tclasses.max())\n",
    "    #, \"quantiles\": (tclasses1.rdiv(tclasses.max()), tclasses2.rdiv(tclasses.max()))\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylim\": (1, 20)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 20, 10)\n",
    "    , \"ylabel\": \"Times Smaller (Classes)\"\n",
    "    #, \"yticks2\": \n",
    "    #     zip([11, 10, 9, 5, 4],\n",
    "    #         [f\"{1/max(tclasses.rdiv(tclasses.max())[s])* 100:0.1f}%\" for s in strategies ]\n",
    "    #     )\n",
    "    , \"percent\": False\n",
    "    , \"best\": max\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Bytes Over Time (s)\"\n",
    "    , \"data\":  tbytes.rdiv(tbytes.max())\n",
    "    , \"ylim\": (1, 20)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 20, 10)\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylabel\": \"Times Smaller (Bytes)\"\n",
    "    , \"percent\": False\n",
    "    , \"best\": max\n",
    "    }\n",
    "    \n",
    "   # (\"Mean Percentage of Classes Left\", dfCs, lambda x: x.mean()), \n",
    "   # (\"Mean Percentage of Bytes Left\", dfBs, lambda x: x.mean()),\n",
    "   # (\"Moving Geometric Mean of Relative Reduction of Classes\", times[0], lambda x: x.agg(stats.gmean)), \n",
    "   # (\"Moving Geometric Mean of Relative Reduction of Bytes\", times[1], lambda x: x.agg(stats.gmean)),\n",
    "   # (\"Median Percentage of Classes Left\", dfCs, lambda x: x.median()), \n",
    "   # (\"Median Percentage of Bytes Left\", dfBs, lambda x: x.median()),  \n",
    "]\n",
    "\n",
    "for ax, diagram in zip(axes.flatten(), diagrams):\n",
    "    data = diagram[\"data\"]\n",
    "   \n",
    "    pretty(ax)\n",
    "    for s in sorted(strategies, key=lambda x: -diagram[\"best\"](data[x])):\n",
    "        ax.plot(data.index * 60, data[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "        \n",
    "        v = ax.hlines(diagram[\"best\"](data[s]),(data.index * 60).min(), (data.index * 60).max())\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "        quantiles = diagram.get(\"quantiles\", None)\n",
    "        if quantiles:\n",
    "            low,high = quantiles\n",
    "            ax.fill_between(low.index * 60, low[s], high[s], label=labels[s], color=shade[s], linestyle=styles[s])\n",
    "            #ax.plot(high.index * 60, high[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "            \n",
    "        \n",
    "    ylim = diagram.get(\"ylim\", (0, data[strategies].max().max()))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "    yticks = diagram.get(\"yticks\", np.linspace(*ylim, 6).round())\n",
    "    ax.set_yticks([],minor=True)\n",
    "    ax.set_yticks(yticks)\n",
    "    yformat = diagram[\"format\"]\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(yformat))\n",
    "    \n",
    "    ax.set_ylabel(diagram.get(\"ylabel\"))\n",
    "    \n",
    "    \n",
    "    #ax.set_yscale(\"log\")\n",
    "    #ticks = list(np.linspace(m[\"logic\"].min(), 0.4, 7))\n",
    "    #ticks.append(1)\n",
    "    \n",
    "    ax.set_title(diagram[\"title\"])\n",
    "    \n",
    "    if diagram.get(\"percent\", False):\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.yaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1, 0))\n",
    "    else: \n",
    "        ax2 = ax.twinx()\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        ax2.set_ylim(*ylim)\n",
    "        ax2.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "        yticks, ytickslabels = zip(\n",
    "            *diagram.get(\"yticks2\",\n",
    "                        [ (d, f\"{1/d * 100:0.1f}%\") for d in (diagram[\"best\"](data[s]) for s in strategies)\n",
    "                        ]\n",
    "            ))\n",
    "        ax2.set_yticks(yticks)\n",
    "        ax2.set_yticklabels(ytickslabels)\n",
    "        ax2.set_yticks([],minor=True)\n",
    "        \n",
    "        ax2.invert_yaxis()\n",
    "        ax.invert_yaxis()\n",
    "      \n",
    "    ax.set_xlim(0,3600)\n",
    "    ax.set_xticks(np.linspace(0,3600, 7))\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x:0.0f}'))\n",
    " \n",
    "axes[0][0].legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"by-time.eps\")\n",
    "fig.savefig(\"by-time.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_xmin = 10\n",
    "bytepm = (tbytes[\"items+hdd\"][60 - last_xmin] - tbytes[\"items+hdd\"][60]) / last_xmin \n",
    "mins = (tbytes[\"items+hdd\"][59] - tbytes[\"logic+ddmin\"][60]) / bytepm\n",
    "print (bytepm, mins)\n",
    "\n",
    "last_xmin = 10\n",
    "bytepm = (tbytes[\"items+hdd\"][60 - last_xmin] - tbytes[\"items+hdd\"][60]) / last_xmin \n",
    "mins = (tbytes[\"items+hdd\"][59] - tbytes[\"logic+ddmin\"][60]) / bytepm\n",
    "print (bytepm, mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbytes[(tbytes < tbytes[\"classes\"][60])].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.groupby(\"strategy\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "iter_maxes = full.iters.unstack(\"strategy\").max()\n",
    "\n",
    "glob = Path(\"result/full/\").glob(\"url*/*\")\n",
    "columns = [\"name\", \"predicate\", \"strategy\", \"time\", \"classes\", \"bytes\", \"iters\"]\n",
    "data = pd.DataFrame(columns = columns)\n",
    "j = 0 \n",
    "for b in glob:\n",
    "    name, predicate = b.relative_to(\"result/full\").parts\n",
    "    if not predicate in {\"cfr\", \"procyon\", \"fernflower\"}: continue\n",
    "    print(name, predicate)\n",
    "    j += 1\n",
    "    #if j > 1: break\n",
    "    try:\n",
    "        metrics = list(b.glob(\"*/workfolder/metrics.csv\"))\n",
    "        if not metrics: continue\n",
    "        for i in metrics:\n",
    "            strat, *_ = i.relative_to(b).parts\n",
    "            m = pd.read_csv(i)\n",
    "            \n",
    "            m.time = m.time.floordiv(15) + 1\n",
    "            x = m[m.judgment == \"success\"]\\\n",
    "                .groupby(\"time\")[[\"classes\", \"bytes\"]]\\\n",
    "                .min()\\\n",
    "                .reindex(index=range(0, 241))\\\n",
    "                .expanding().min()\\\n",
    "                .fillna(m.loc[0][[\"classes\",\"bytes\"]])\n",
    "            \n",
    "            x = pd.DataFrame(x, columns=columns)\n",
    "            x.time = x.index * 15\n",
    "            x.name = name\n",
    "            x.strategy = strat\n",
    "            x.predicate = predicate\n",
    "            x.iters = m.groupby(\"time\")\\\n",
    "                .folder.max().reindex(index=range(0,241)).expanding().max().fillna(0)\n",
    "            \n",
    "            data = data.append(x, sort=True)\n",
    "        \n",
    "            # y = m[m.judgment == \"success\"]\\\n",
    "            #     .groupby(\"folder\")[[\"classes\", \"bytes\"]]\\\n",
    "            #     .min()\\\n",
    "            #     .reindex(index=range(0, iter_maxes.max()))\\\n",
    "            #     .expanding().min()\n",
    "    except Exception as e :\n",
    "        print(\"WARNING\", e, i)\n",
    "        continue\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "def handler(ax, tp): \n",
    "    pretty(ax)\n",
    "\n",
    "    v = data[data.time <= 0].groupby([\"name\", \"predicate\",\"strategy\"])\\\n",
    "        [tp].min()\n",
    "\n",
    "    benchmarks = data.groupby([\"name\", \"predicate\"])[tp].max()\n",
    "    \n",
    "    ax.set_ylim(0, len(benchmarks))\n",
    "    ax.set_yticks(np.linspace(0, len(benchmarks), 8).round())\n",
    "\n",
    "    #ax.set_xscale(\"log\")\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_xticks(np.linspace(0,1, 5))\n",
    "    \n",
    "    t = v.unstack('strategy') \n",
    "    curves = [ ax.plot(sorted((t[s] / benchmarks)), \n",
    "                      list([i + 1 for i,_ in enumerate(benchmarks)]), \n",
    "                      color=colors[s], \n",
    "                      linestyle=styles[s],\n",
    "                      label=labels[s]\n",
    "                     )[0]\n",
    "             for s in strategies\n",
    "            ]\n",
    "    \n",
    "    gmean = stats.gmean(benchmarks)\n",
    "    lines = [ \n",
    "        ax.vlines((stats.gmean(t[s]) / gmean), 0, len(benchmarks),)\n",
    "        for s in strategies\n",
    "    ]\n",
    "    for line, s in zip(lines, strategies):\n",
    "        line.set_color(colors[s])\n",
    "        line.set_linestyle(\":\")\n",
    "\n",
    "\n",
    "    def update(i):\n",
    "        \n",
    "        t = data[data.time <= i * 15].groupby([\"name\", \"predicate\",\"strategy\"])[tp].min().unstack('strategy')\n",
    "        for l, s in zip(curves, strategies):\n",
    "            l.set_xdata(sorted((t[s] / benchmarks)))\n",
    "            \n",
    "        for l, s in zip(lines, strategies):\n",
    "            seg = l.get_segments()\n",
    "            seg[0][0,0] = (stats.gmean(t[s]) / gmean)\n",
    "            seg[0][1,0] = (stats.gmean(t[s]) / gmean)\n",
    "            l.set_segments(seg)\n",
    "            \n",
    "        ax.set_title(f\"Distribution of Reduction of {tp} After {i*15:4.0f} s\")\n",
    "        return lines,curves,ax\n",
    "\n",
    "    return update\n",
    "\n",
    "\n",
    "updates = []\n",
    "for ax, tp in zip(axes, [\"classes\", \"bytes\"]):\n",
    "    updates.append(handler(ax, tp))\n",
    "    \n",
    "\n",
    "ax.legend()\n",
    "\n",
    "def updateboth(i):\n",
    "    print(f\"update {i}\")\n",
    "    return updates[0](i) + updates[1](i)\n",
    "\n",
    "#updateboth(30)\n",
    "\n",
    "anim = FuncAnimation(fig, updateboth, frames=np.arange(0, 241), interval=200)\n",
    "anim.save('bytes.gif', dpi=80, writer='imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Plot a scatter that persists (isn't redrawn) and the initial line.\n",
    "x = np.arange(0, 20, 0.1)\n",
    "ax.scatter(x, x + np.random.normal(0, 3.0, len(x)))\n",
    "line, = ax.plot(x, x - 5, 'r-', linewidth=2)\n",
    "\n",
    "def update(i):\n",
    "    label = 'timestep {0}'.format(i)\n",
    "    print(label)\n",
    "    # Update the line and the axes (with a new xlabel). Return a tuple of\n",
    "    # \"artists\" that have to be redrawn for this frame.\n",
    "    line.set_ydata(x - 5 + i)\n",
    "    ax.set_xlabel(label)\n",
    "    return line, ax\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, 10), interval=200)\n",
    "anim.save('line.gif', dpi=80, writer='imagemagick')\n",
    "#if __name__ == '__main__':\n",
    "#    # FuncAnimation will call the 'update' function for each frame; here\n",
    "#    # animating over 10 frames, with an interval of 200ms between frames.\n",
    "#    \n",
    "#    if len(sys.argv) > 1 and sys.argv[1] == 'save':\n",
    "#        \n",
    "#    else:\n",
    "#        # plt.show() will just loop the animation forever.\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "iter_maxes = full.iters.unstack(\"strategy\").max()\n",
    "\n",
    "glob = Path(\"result/full/\").glob(\"url*/*\")\n",
    "dfCs = []\n",
    "dfBs = []\n",
    "j = 0 \n",
    "for b in glob:\n",
    "    if not b.name in {\"cfr\", \"procyon\", \"fernflower\"}: continue\n",
    "    j += 1\n",
    "    #if j > 10: break\n",
    "    try:\n",
    "        dfC = pd.DataFrame()\n",
    "        dfB = pd.DataFrame()\n",
    "        metrics = list(b.glob(\"*/workfolder/metrics.csv\"))\n",
    "        if not metrics: continue\n",
    "        for i in metrics:\n",
    "            strat, *_ = i.relative_to(b).parts\n",
    "            # print(i)\n",
    "            m = pd.read_csv(i)\n",
    "            x = m[m.judgment == \"success\"]\\\n",
    "                .groupby(\"folder\")[[\"classes\", \"bytes\"]]\\\n",
    "                .min()\\\n",
    "                .rdiv(m.iloc[0][[\"classes\", \"bytes\"]])\\\n",
    "                .reindex(index=range(0, iter_maxes.max()))\\\n",
    "                .expanding().max()\\\n",
    "                .fillna(1)\n",
    "        \n",
    "            dfC = dfC.assign(**{strat: x[\"classes\"]})\n",
    "            dfB = dfB.assign(**{strat: x[\"bytes\"]})\n",
    "        \n",
    "        dfCs.append(dfC)\n",
    "        dfBs.append(dfB)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"WARNING\", i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(11,4), sharex=True)\n",
    "\n",
    "graphs = [ \n",
    "  #  (\"Mean Percentage of Classes Left\", dfCs, lambda x: x.mean()), \n",
    "  #  (\"Mean Percentage of Bytes Left\", dfBs, lambda x: x.mean()),\n",
    "    (\"Moving Geometric Mean of Relative Reduction of Classes\", dfCs, lambda x: x.agg(stats.gmean)), \n",
    "    (\"Moving Geometric Mean of Relative Reduction of Bytes\", dfBs, lambda x: x.agg(stats.gmean)),\n",
    " #   (\"Median Percentage of Classes Left\", dfCs, lambda x: x.median()), \n",
    "  #  (\"Median Percentage of Bytes Left\", dfBs, lambda x: x.median()),  \n",
    "]\n",
    "\n",
    "for ax, (title, dfc, fn) in zip(axes.flatten(), graphs):\n",
    "    m = fn(pd.concat(dfc).groupby(\"folder\"))\n",
    "    for s in strategies:\n",
    "        indices = m.index[range(0, maxes[s])]\n",
    "        ax.plot(indices, m[s].iloc[indices], label=s, color=colors[s])\n",
    "        \n",
    "        v = ax.hlines(max(m[s]),0, 3600)\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "    ax.set_ylim(0,m[\"logic\"].max() * 1.1)\n",
    "    ax.set_xlim(0,iter_maxes.max())\n",
    "    ax.set_xticks(np.linspace(0,iter_maxes.max(), 7))\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'x {x:0.0f}'))\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x:0.0f}'))\n",
    "    \n",
    "    pretty(ax)\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"by-iters.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.iters.unstack(\"strategy\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(11,6), sharey=True, sharex=True)\n",
    "\n",
    "graphs = [\n",
    "    (\"Mean Percentage of Classes Left\", dfCs, lambda x: x.mean()), \n",
    "    (\"Mean Percentage of Bytes Left\", dfBs, lambda x: x.mean()),\n",
    "    (\"Median Percentage of Classes Left\", dfCs, lambda x: x.median()), \n",
    "    (\"Median Percentage of Bytes Left\", dfBs, lambda x: x.median()),  \n",
    "]\n",
    "\n",
    "for ax, (title, dfc, fn) in zip(axes.flatten(), graphs):\n",
    "    m = fn(pd.concat(dfc, keys=range(0, len(dfc))).groupby(\"time\"))\n",
    "    for s in strategies:\n",
    "        ax.plot(m.index * 60, m[s], label=s, color=colors[s])\n",
    "        \n",
    "        v = ax.hlines(min(m[s]),0, 3600)\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_xlim(0,3600)\n",
    "    ax.set_xticks(np.linspace(0,3600, 7))\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x*100:0.0f}%'))\n",
    "    ax.xaxis.set_maj  or_formatter(plt.FuncFormatter(lambda x, pos: f'{x:0.0f} s'))\n",
    "    \n",
    "    pretty(ax)\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"new-approach.pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra evaluation\n",
    "\n",
    "Here i have left some space for some extra interesting questions: \n",
    "\n",
    "The first question is how the size of the input in bytes affect the time to setup and run the predicate. In this case it is fernflower.\n",
    "\n",
    "The interesting thing here is that the execution time of the predicate is dependent on the size of the input, and by testing small inputs it can be up to 10 times faster than testing the large inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    metrics = pd.read_csv(\"result/full/url0e7ea11f42_rbouckaert_DensiTree/fernflower/logic/workfolder/metrics.csv\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(7,7), sharex=True)\n",
    "\n",
    "\n",
    "    for key, ax in zip([\"setup time\", \"run time\"], axes):\n",
    "        ax.scatter(metrics.bytes, metrics[key])\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x:0.1f} s'))\n",
    "        ax.set_xlim(0, metrics.bytes.max() * 1.1)\n",
    "        ax.set_ylim(0, metrics[key].max() * 1.1)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.set_title(key)\n",
    "        pretty(ax)\n",
    "        \n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x/1000:0.0f} Kb'))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part\n",
    "\n",
    "Here we analyse given only 1 bug being preserved by Javac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_results = pd.read_csv(\"result/part/result.csv\").set_index([\"name\", \"predicate\",\"strategy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14,2))\n",
    "\n",
    "timeouts = (part_results.status == \"timeout\").groupby(\"strategy\").mean()\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "pretty(ax)\n",
    "x = ax.barh(\n",
    "        strategies, \n",
    "        [timeouts[s] * 100 for s in strategies], \n",
    "        color=[colors[s] for s in strategies]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative reduction\n",
    "\n",
    "In our first experiment we are going to look at comparative final size, and time. We use the geometric mean, so that we can compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 3600\n",
    "part = part_results.copy()\n",
    "part.time.loc[part.status == \"timeout\"] = TIMEOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvalues = part.filter([\"bytes\", \"classes\", \"time\"], axis=1)\\\n",
    "    .unstack(\"strategy\")\\\n",
    "    .agg(stats.gmean)\\\n",
    "    .unstack()\n",
    "\n",
    "v = part.filter([\"initial-bytes\", \"initial-classes\"], axis=1).unstack(\"strategy\")\\\n",
    "    .agg(stats.gmean)\\\n",
    "    .unstack()[\"classes\"]\\\n",
    "    .rename(lambda a: a.lstrip(\"initial-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvalues.round(1)[list(reversed(strategies))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare them on how much reduction each of them have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(keyvalues.loc[[\"bytes\",\"classes\"]].div(v, axis='rows') * 100).round(1)[list(reversed(strategies))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = draw_diagram(part)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
