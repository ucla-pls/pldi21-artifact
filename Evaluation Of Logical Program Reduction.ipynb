{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook, which contains the results of running our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "def pretty(ax):\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    for spine in [ax.spines['left'], ax.spines['bottom'], ax.spines[\"right\"], ax.spines['top']]:\n",
    "        spine.set_position((\"outward\", 5))\n",
    "        spine.set_color(\"gray\")\n",
    "        \n",
    "    for axis in [ax.yaxis, ax.xaxis]:\n",
    "        for x in axis.get_major_ticks():\n",
    "            x.label1.set_color(\"gray\")\n",
    "            x.label2.set_color(\"gray\")\n",
    "            x.tick1line.set_color(\"gray\")\n",
    "            x.tick2line.set_color(\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full\n",
    "\n",
    "This section covers the evaluation where we preserve the full bug. We start by loading the the data and indexing by `name`, `predicate`, and `strategy`. The data have been computed and put in `results/result.csv` by our evalutation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"result/full/result.csv\").set_index([\"name\", \"predicate\",\"strategy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A single line of our data looks like this, we store the follwing data: \n",
    "\n",
    "*  `bugs` which contain the number of lines in the cleaned up bug-report\n",
    "\n",
    "*  `initial-scc` and `scc` contain the number of strongly connected components before and after reduction,\n",
    "\n",
    "*  `initial-classes` and `classes` contain the number of classes before and after reduction,\n",
    "\n",
    "*  `initial-bytes` and `bytes` contain the number of bytes before and after reduction,\n",
    "\n",
    "*  `iters` which contain the number of invocations of the predicate, \n",
    "\n",
    "*  `searches` the number of binary searches made by algorithm\n",
    "\n",
    "*  `time` which records the time to reach the final successfull solution,\n",
    "\n",
    "*  `status` which records whether the reduction completed correctly,\n",
    "\n",
    "*  `verify` which records information about if bug is preserved.\n",
    "\n",
    "Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\"url0067cdd33d_goldolphin_Mi\", \"cfr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\"url0067cdd33d_goldolphin_Mi\", \"cfr\", \"items+logic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfs = pd.read_csv(\"result/full/sizes/cnfs.csv\").set_index(\"name\")\n",
    "index = results.unstack(\"strategy\").index\n",
    "bybench = pd.DataFrame(dict(clauses=[ cnfs.clauses[n] for (n,v) in index], edges=[ cnfs.edges[n] for (n,v) in index]), index=index)\n",
    "bybench[\"graphscore\"] = bybench.edges / bybench.clauses\n",
    "bybench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10,5), sharey=True)\n",
    "\n",
    "bugs = results[\"bugs\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_bytes = results[\"initial-bytes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_classes = results[\"initial-classes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_variables = results[\"initial-scc\"].unstack(\"strategy\")[\"items+logic\"]\n",
    "clauses = cnfs.clauses[results.index]\n",
    "\n",
    "number_of_benchmarks = len(bugs.index)\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Histogram of Classes\"\n",
    "    , \"data\": initial_classes\n",
    "    , \"xlabel\": \"Classes\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Bytes (in MB)\"\n",
    "    , \"data\": initial_bytes\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000000 :0.2f}'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.0f} KB'\n",
    "    , \"xlabel\": \"Bytes (in MB)\"\n",
    "    },\n",
    "\n",
    "    { \"title\": \"Histogram of Bugs\"\n",
    "    , \"data\": bugs\n",
    "    , \"xlabel\": \"Errors in Output\"\n",
    "    , \"format\" : lambda x, pos: f'{x :0.1f}'\n",
    "    , \"splits\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    },\n",
    "    \n",
    "    { \"title\": \"Histogram of Variables\"\n",
    "    , \"data\": initial_variables\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.0f}k'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.1f}k'\n",
    "    , \"xlabel\": \"Reducible Items\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Clauses\"\n",
    "    , \"data\": bybench.clauses\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.0f}k'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.1f}k'\n",
    "    , \"xlabel\": \"Clauses\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Procentage\"\n",
    "    , \"data\": bybench.graphscore\n",
    "    , \"xformat\" : lambda x, pos: f'{x * 100 :0.0f}%'\n",
    "    , \"format\" : lambda x, pos: f'{x * 100 :0.0f}%'\n",
    "    , \"xlabel\": \"Edges per Clause\"\n",
    "    , \"splits\": np.linspace(bybench.graphscore.min(), 1, 11)\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "axes[0][0].set_ylabel(\"Bencmarks\")\n",
    "axes[1][0].set_ylabel(\"Bencmarks\")\n",
    "for ax, diagram in zip(axes.flatten(), diagrams):\n",
    "    pretty(ax)\n",
    "    \n",
    "    data = diagram[\"data\"]\n",
    "    xlim = (data.min(), data.max())\n",
    "    splits = diagram.get(\"splits\",np.linspace(*xlim, 11).round(0))\n",
    "    \n",
    "    \n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xticks(splits[::2])\n",
    "    ax.set_xticks(splits, minor=True)\n",
    "    \n",
    "    \n",
    "    ylim = (0, number_of_benchmarks)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks(np.linspace(*ylim, 8).round(0))\n",
    "    if not ax in (axes[0][0], axes[1][0]):\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        for x in ax.yaxis.get_major_ticks():\n",
    "            x.set_visible(False)\n",
    "    ax.set_xlabel(diagram[\"xlabel\"])\n",
    "   \n",
    "    blocks = ax.hist(diagram[\"data\"], splits, color=\"black\", rwidth=0.75)\n",
    "    \n",
    "    \n",
    "    xformat = diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(xformat))\n",
    "    #ax.xaxis.set_tick_params(rotation=70)\n",
    "    \n",
    "    gmean = stats.gmean(diagram[\"data\"])\n",
    "    v = ax.vlines(gmean, *ylim)\n",
    "    v.set_color(\"gray\")\n",
    "    v.set_linestyle(\":\")\n",
    "    \n",
    "    t = ax.text(gmean + (xlim[1] - xlim[0]) * 0.05, ylim[1] * 0.94, \"GM \" + diagram.get(\"format\", xformat)(gmean, 0))\n",
    "    t.set_color(\"gray\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.18)\n",
    "fig.savefig(\"benchmarks.eps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing two startegies: \n",
    "\n",
    "- classes\n",
    "- logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = list(reversed([\"classes\", \"items+logic\"]))\n",
    "\n",
    "p = [\"#0a1058\", \"#ee4242\", \"#ff9135\", \"#9857ff\", \"#4cb2ff\"]\n",
    "\n",
    "\n",
    "colors = { \"classes\" : \"#5F99E7\",  \"items+logic\": \"#1956A7\"}\n",
    "shade  = { \"classes\" : \"#F6F1B0\",  \"items+logic\": \"#B0B6F6\"}\n",
    "labels = { \"classes\" : \"J-Reduce\", \"items+logic\": \"Our Reducer\"}\n",
    "styles = { \"classes\" : \"--\",       \"items+logic\": \"-\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  How many procent do each strategy time out on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10,0.7))\n",
    "\n",
    "timeouts = (results.status == \"timeout\").groupby(\"strategy\").mean()\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "pretty(ax)\n",
    "x = ax.barh(\n",
    "        [labels[s] + \" \" + str((100 - timeouts[s] * 100).round(1)) + \"%\" for s in strategies], \n",
    "        [timeouts[s] * 100 for s in strategies], \n",
    "        color=[colors[s] for s in strategies],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many benchmarks do 'classes' produce fewer classes than 'logic', and how many of them \n",
    "  are not due to timeouts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outperforms = []\n",
    "for (b, p, x) in results.index:\n",
    "    if x != \"classes\": continue\n",
    "    c = results.classes\n",
    "    if c.loc[(b, p, x)] < c.loc[(b, p, \"items+logic\")]:\n",
    "        outperforms.append(\n",
    "            ( b + \"/\" + p\n",
    "            , (c.loc[(b, p, \"items+logic\")] / c.loc[(b, p, \"classes\")]).round(1)\n",
    "            , results.loc[(b,p,\"items+logic\")].status\n",
    "            )\n",
    "        )\n",
    "len(outperforms), len([x for x in outperforms if x[2] != \"timeout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\"url9200ed8692_olabini_ioke\", \"fernflower\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is 'classes' and 'jreduce' comparable in classes, bytes, and time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ## Comparative reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our comparative reducetion results we will update the times of all timeout items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 24 * 60 * 60\n",
    "full = results.copy()\n",
    "full.loc[full.status == \"timeout\", \"time\"] = TIMEOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first experiment we are going to look at comparative final size, and time. We use the geometric mean, so that we can compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = full[[\"time\", \"bytes\", \"classes\"]].groupby(\"strategy\").agg(stats.gmean)\n",
    "r.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r.loc[\"classes\"] / r.loc[\"jreduce\"] * 100 - 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r.loc[\"classes+logic\"] / r.loc[\"classes\"] * 100 - 100).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r.loc[\"classes\"] / r.loc[\"items+logic\"]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r.loc[\"items+logic\"] / r.loc[\"classes\"]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_diagram(full):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10,3.5), sharey=True)\n",
    "    \n",
    "    diagrams = [\n",
    "        { \"title\": \"Finished Programs over Time\"\n",
    "        , \"xformat\": lambda x, pos: f'{x/3600:0.0f}:{x%3600/60:02.0f}'\n",
    "        , \"labelformat\": lambda x: f'{x:0.1f}s'\n",
    "        , \"data\": lambda s: list(sorted(d for d in full[\"time\"].unstack(\"strategy\")[s] if d < TIMEOUT))\n",
    "        , \"xlim\": (0, 10 * 3600)\n",
    "        , \"xticks\": np.linspace(0, 10*3600, 6)\n",
    "        , \"xlabel\": \"Time Spend (h:mm)\"\n",
    "        , \"percent\": False\n",
    "        },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"labelformat\": lambda x: f'{x*100:0.1f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"classes\"].unstack(\"strategy\")[s] / initial_classes)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Classes)\"\n",
    "        },\n",
    "        # { \"title\": \"Finished Programs over Invocations\"\n",
    "        # , \"xformat\": lambda x, pos: f'{x:0.0f}'\n",
    "        # , \"data\": lambda s: sorted(full[\"iters\"].unstack(\"strategy\")[s])\n",
    "        # , \"xlim\": (0, full[\"iters\"].max())\n",
    "        # , \"xlabel\": \"Invocations Made\"\n",
    "        # },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"labelformat\": lambda x: f'{x*100:0.1f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"bytes\"].unstack(\"strategy\")[s] / initial_bytes)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Bytes)\"\n",
    "        },\n",
    "\n",
    "        \n",
    "        ]\n",
    "\n",
    "    for diagram, ax in zip(diagrams, axes.flatten()):\n",
    "        maxx, minx = 0, 1000000000\n",
    "        pretty(ax)\n",
    "       \n",
    "        strats = sorted(strategies, key=lambda s: np.mean(diagram[\"data\"](s)))\n",
    "        for s in strats:\n",
    "            data = diagram[\"data\"](s)\n",
    "            ax.plot(data, [i + 1 for i,_ in enumerate(data)], \n",
    "                    label=labels[s], \n",
    "                    linestyle=styles[s],\n",
    "                    color=colors[s])\n",
    "            maxx = max(maxx, max(data))\n",
    "            minx = min(minx, min(data))\n",
    "            \n",
    "            mean = stats.gmean(data)\n",
    "            for i, x in enumerate(data):\n",
    "                if x > mean: \n",
    "                    index = i + 1\n",
    "                    break\n",
    "            \n",
    "            ax.scatter(mean, index, color=colors[s])\n",
    "            if s == \"items+logic\":\n",
    "                loc = (mean + 6 / 100 * diagram[\"xticks\"][-1], index * 1.05 - 2)\n",
    "            else:\n",
    "                loc = (mean + 5 / 100 * diagram[\"xticks\"][-1], index - 11)\n",
    "            \n",
    "            ax.text(*loc, diagram[\"labelformat\"](mean)\n",
    "                    , color=colors[s]\n",
    "                    , bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"white\")\n",
    "                   )\n",
    "            \n",
    "        minx = max(1, minx)\n",
    "        \n",
    "\n",
    "        xlim = diagram.get(\"xlim\", (0, maxx))\n",
    "        ax.set_xlim(*xlim)\n",
    "        xtics = diagram.get(\"xticks\", np.linspace(*xlim, 7))\n",
    "        ax.set_xticks(xtics)\n",
    "        \n",
    "        ylim = 0, number_of_benchmarks\n",
    "        ax.set_yticks(np.linspace(*ylim, 7).round())\n",
    "        ax.set_yticks([], minor=True)\n",
    "        ax.set_ylim(*ylim)\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(\"Benchmarks\")\n",
    "        \n",
    "        \n",
    "        if diagram.get(\"percent\", False):\n",
    "            ax2 = ax.twinx()\n",
    "            pretty(ax2)\n",
    "            \n",
    "            yticks = [227, 200]\n",
    "            strats = sorted(strategies, key=lambda s: -len(diagram[\"data\"](s)))\n",
    "            ytickslabels = [f\"{(len(diagram['data'](s)) - 1) / number_of_benchmarks * 100:0.0f} %\" for s in strats]\n",
    "            ax2.set_yticks(yticks)\n",
    "            ax2.set_yticklabels(ytickslabels)\n",
    "            #ax2.set_ylabel(\"Completion Rate\")\n",
    "        \n",
    "        \n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')))\n",
    "        \n",
    "        \n",
    "        v = ax.hlines(round(number_of_benchmarks/2),*xlim)\n",
    "        v.set_color(\"gray\")\n",
    "        v.set_linestyle(\":\")\n",
    "                            \n",
    "                            \n",
    "        #v = ax.hlines(round(number_of_benchmarks * 0.95),*xlim)\n",
    "        #v.set_color(\"gray\")\n",
    "        #v.set_linestyle(\":\")\n",
    "                              \n",
    "        if ax == axes[0]:\n",
    "            # v = ax.vlines(full.time.unstack(\"strategy\")[\"classes\"].max() ,*ylim)\n",
    "            # v.set_color(\"gray\")\n",
    "            # v.set_linestyle(\":\")\n",
    "            #                 \n",
    "            # v = ax.vlines(full.time.unstack(\"strategy\")[\"items+logic\"].quantile(0.95) ,*ylim)\n",
    "            # v.set_color(\"gray\")\n",
    "            # v.set_linestyle(\":\")\n",
    "                            \n",
    "            # t = ax.text(xlim[1] * 0.45, 54 + 5, \"ONE BUG\")\n",
    "            # t.set_color(\"gray\")\n",
    "            t = axes[0].text(15005, round(len(data)/2) + 4.5, \"MEDIAN\")\n",
    "            t.set_color(\"gray\")\n",
    "                            \n",
    "            \n",
    "        \n",
    "        ax.set_xlabel(diagram[\"xlabel\"])    \n",
    "    \n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.13)\n",
    "    axes[2].legend(loc=\"lower right\")\n",
    "    return fig\n",
    "\n",
    "fig = draw_diagram(full)\n",
    "fig.savefig(\"timings.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs are formatted like the previous article: In the top row we have number programs that complete before a certain time and iterations. In the bottom row we have the number of programs that have been reduced to a size below a certian number of bytes or classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbytes = pd.read_csv(\"result/full/bytes.csv\").groupby(\"strategy\").agg(stats.gmean).T.rename(int)\n",
    "tclasses = pd.read_csv(\"result/full/classes.csv\").groupby(\"strategy\").agg(stats.gmean).T.rename(int)\n",
    "\n",
    "fclasses = results.classes.groupby(\"strategy\").agg(stats.gmean)\n",
    "fbytes = results.bytes.groupby(\"strategy\").agg(stats.gmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10,6))\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Mean Classes Left Over Time\"\n",
    "    , \"data\":  tclasses\n",
    "    # , \"quantiles\": (tclasses1, tclasses2)\n",
    "    , \"format\": lambda x, pos: f\"{x:0.0f}\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Mean Classes Left\"\n",
    "    , \"best\": fclasses\n",
    "    },\n",
    "    { \"title\": \"Mean Bytes Left Over Time (h:m)\"\n",
    "    , \"data\":  tbytes\n",
    "    , \"format\": lambda x, pos: f\"{x / 1000:0.0f} KB\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Mean Bytes Left\"\n",
    "    , \"best\": fbytes\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Classes Over Time\"\n",
    "    , \"data\":  tclasses.rdiv(tclasses.max())\n",
    "    #, \"quantiles\": (tclasses1.rdiv(tclasses.max()), tclasses2.rdiv(tclasses.max()))\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylim\": (1, 25)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 25, 7)\n",
    "    , \"ylabel\": \"Mean Times Smaller (Classes)\"\n",
    "    , \"xlabel\": \"Time Spend (h:mm)\"\n",
    "    #, \"yticks2\": \n",
    "    #     zip([11, 10, 9, 5, 4],\n",
    "    #         [f\"{1/max(tclasses.rdiv(tclasses.max())[s])* 100:0.1f}%\" for s in strategies ]\n",
    "    #     )\n",
    "    , \"percent\": False\n",
    "    , \"best\": fclasses.rdiv(tclasses.max())\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Bytes Over Time\"\n",
    "    , \"data\":  tbytes.rdiv(tbytes.max())\n",
    "    , \"ylim\": (1, 25)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 25, 7)\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylabel\": \"Mean Times Smaller (Bytes)\"\n",
    "    , \"percent\": False\n",
    "    , \"xlabel\": \"Time Spend (h:mm)\"\n",
    "    , \"best\": fbytes.rdiv(tbytes.max())\n",
    "    }\n",
    "    \n",
    "   # (\"Mean Percentage of Classes Left\", dfCs, lambda x: x.mean()), \n",
    "   # (\"Mean Percentage of Bytes Left\", dfBs, lambda x: x.mean()),\n",
    "   # (\"Moving Geometric Mean of Relative Reduction of Classes\", times[0], lambda x: x.agg(stats.gmean)), \n",
    "   # (\"Moving Geometric Mean of Relative Reduction of Bytes\", times[1], lambda x: x.agg(stats.gmean)),\n",
    "   # (\"Median Percentage of Classes Left\", dfCs, lambda x: x.median()), \n",
    "   # (\"Median Percentage of Bytes Left\", dfBs, lambda x: x.median()),  \n",
    "]\n",
    "\n",
    "for ax, diagram in zip(axes.flatten(), diagrams):\n",
    "    data = diagram[\"data\"]\n",
    "   \n",
    "    pretty(ax)\n",
    "    for s in reversed(strategies):\n",
    "        ax.plot(data.index * 60, data[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "        \n",
    "        v = ax.hlines(diagram[\"best\"][s],(data.index * 60).min(), (data.index * 60).max())\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "        quantiles = diagram.get(\"quantiles\", None)\n",
    "        if quantiles:\n",
    "            low,high = quantiles\n",
    "            ax.fill_between(low.index * 60, low[s], high[s], label=labels[s], color=shade[s], linestyle=styles[s])\n",
    "            #ax.plot(high.index * 60, high[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "            \n",
    "        \n",
    "    ylim = diagram.get(\"ylim\", (0, data[strategies].max().max()))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "    yticks = diagram.get(\"yticks\", np.linspace(*ylim, 6).round())\n",
    "    ax.set_yticks([],minor=True)\n",
    "    ax.set_yticks(yticks)\n",
    "    yformat = diagram[\"format\"]\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(yformat))\n",
    "    \n",
    "    ax.set_ylabel(diagram.get(\"ylabel\"))\n",
    "    \n",
    "    xlabel = diagram.get(\"xlabel\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "  \n",
    "    \n",
    "    if diagram.get(\"percent\", False):\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.yaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1, 0))\n",
    "    else: \n",
    "        ax2 = ax.twinx()\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        ax2.set_ylim(*ylim)\n",
    "        ax2.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "        \n",
    "        onehour = (diagram[\"data\"][\"items+logic\"].loc[60])\n",
    "        \n",
    "        v = ax.hlines(onehour,(data.index * 60).min(), (data.index * 60).max())\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    " \n",
    "        \n",
    "        yticks, ytickslabels = zip(\n",
    "            *diagram.get(\"yticks2\",\n",
    "                        [ (d, f\"{1/d * 100:0.1f}%\") for d in (diagram[\"best\"][s] for s in strategies)\n",
    "                        ] + [(onehour, f\"{1/onehour * 100:0.1f}%\")]\n",
    "            ))\n",
    "        ax2.set_yticks(yticks)\n",
    "        ax2.set_yticklabels(ytickslabels)\n",
    "        ax2.set_yticks([],minor=True)\n",
    "        \n",
    "        ax2.invert_yaxis()\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "    xlim = (0, 60 * 60 * 2)\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xticks(np.linspace(*xlim, 5))\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{x/3600:0.0f}:{x%3600/60:02.0f}'))\n",
    "\n",
    "    # if xlabel is None:\n",
    "    #     ax.xaxis.tick_top()\n",
    "    #     ax.spines[\"bottom\"].set_visible(False)\n",
    "    #     ax.spines[\"top\"].set_visible(True)\n",
    "    \n",
    "   \n",
    "axes[0][0].legend()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.20)\n",
    "fig.savefig(\"by-time.eps\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xclasses = pd.read_csv(\"result/full/classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = xclasses.set_index([\"name\",\"predicate\", \"strategy\"])\n",
    "\n",
    "a[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
