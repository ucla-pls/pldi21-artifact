{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Evaluation\n",
    "This notebook contains the evaluation of our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "\n",
    "def pretty(ax):\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    for spine in [ax.spines['left'], ax.spines['bottom'], ax.spines[\"right\"], ax.spines['top']]:\n",
    "        spine.set_position((\"outward\", 5))\n",
    "        spine.set_color(\"gray\")\n",
    "        \n",
    "    for axis in [ax.yaxis, ax.xaxis]:\n",
    "        for x in axis.get_major_ticks():\n",
    "            x.label1.set_color(\"gray\")\n",
    "            x.label2.set_color(\"gray\")\n",
    "            x.tick1line.set_color(\"gray\")\n",
    "            x.tick2line.set_color(\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section covers the evaluation where we preserve the full bug. We start by loading the the data and indexing by `name`, `predicate`, and `strategy`. The data have been computed and put in `results/full/result.csv` by our evalutation framework. This evaluation is currently pointed at `pre-calculated` which contains the data from one of oure runs. It's sligthly different from the results we have in the paper but only in running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if you want to use the data you generated your self.\n",
    "# folder  = Path(\"result/full/\")\n",
    "# use this to reproduce the result of the paper\n",
    "folder = Path(\"pre-calculated\")\n",
    "results = pd.read_csv(folder / \"result.csv\").set_index([\"name\", \"predicate\",\"strategy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an line for each combination of benchmark, predicate (decompiler), and strategy. We have the following \n",
    "strategy:\n",
    "\n",
    "*  `jreduce`: the original almost unmodified jreduce (see patch `nix/old-jreduce/reduce-util.patch`)\n",
    "*  `classes`: our new version of jreduce with extended logging.\n",
    "*  `items+graph+first` and `items+graph+last` reduction on the granuality of final version but approximates\n",
    "   the logic with a graph were we either choose the first or last positive and negative element in each clause.\n",
    "*  `items+logic` the final version as described in the paper.\n",
    "\n",
    "A single line of our data looks like this, we store the follwing data: \n",
    "\n",
    "*  `bugs` which contain the number of lines in the cleaned up bug-report\n",
    "\n",
    "*  `initial-scc` and `scc` contain the number of strongly connected components before and after reduction,\n",
    "    (For `items+logic` this contains the number of variables, and for `jreduce` 0 because we do not have access to the number of scc)\n",
    "\n",
    "*  `initial-classes` and `classes` contain the number of classes before and after reduction,\n",
    "\n",
    "*  `initial-bytes` and `bytes` contain the number of bytes before and after reduction,\n",
    "\n",
    "*  `initial-lines` and `lines` contain the number of lines in the decompiled code (for `jreduce` this is 0 because the original `jreduce` did not caputre that data for each iteration),\n",
    "\n",
    "*  `iters` which contain the number of invocations of the predicate, \n",
    "\n",
    "*  `searches` the number of binary searches made by algorithm (ignored by `items+logic`),\n",
    "\n",
    "*  `setup-time` the time before the first iteration,\n",
    "\n",
    "*  `time` which records the time to reach the final successfull solution,\n",
    "\n",
    "*  `status` which records whether the reduction completed correctly,\n",
    "\n",
    "*  `verify` which records information about if bug is preserved.\n",
    "\n",
    "*  `flaky` which records if we have noticed something flaky happining\n",
    "\n",
    "\n",
    "Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[\"url0067cdd33d_goldolphin_Mi\", \"cfr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sadly not part of the paper here is some indept data about the benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(12,5), sharey=True)\n",
    "\n",
    "cnfs = pd.read_csv( folder / \"sizes/cnfs.csv\").set_index(\"name\")\n",
    "index = results.unstack(\"strategy\").index\n",
    "bybench = pd.DataFrame(dict(clauses=[cnfs.clauses[n] for (n,v) in index], edges=[ cnfs.edges[n] for (n,v) in index]), index=index)\n",
    "bybench[\"graphscore\"] = bybench.edges / bybench.clauses\n",
    "\n",
    "bugs = results[\"bugs\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_bytes = results[\"initial-bytes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_classes = results[\"initial-classes\"].unstack(\"strategy\")[\"classes\"]\n",
    "initial_variables = results[\"initial-scc\"].unstack(\"strategy\")[\"items+logic\"]\n",
    "initial_lines = results[\"initial-lines\"].unstack(\"strategy\")[\"items+logic\"]\n",
    "clauses = cnfs.clauses[results.index]\n",
    "\n",
    "number_of_benchmarks = len(bugs.index)\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Histogram of Classes\"\n",
    "    , \"data\": initial_classes\n",
    "    , \"xlabel\": \"Classes\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Bytes (in MB)\"\n",
    "    , \"data\": initial_bytes\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000000 :0.2f}'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.0f} KB'\n",
    "    , \"xlabel\": \"Bytes (in MB)\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Lines\"\n",
    "    , \"data\": initial_lines\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.0f}k'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.1f}k'\n",
    "    , \"xlabel\": \"Lines\"\n",
    "    #, \"splits\": np.linspace(bybench.graphscore.min(), 1, 11)\n",
    "    },\n",
    "\n",
    "    { \"title\": \"Histogram of Bugs\"\n",
    "    , \"data\": bugs\n",
    "    , \"xlabel\": \"Errors in Output\"\n",
    "    , \"format\" : lambda x, pos: f'{x :0.1f}'\n",
    "    , \"splits\": [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    },\n",
    "    \n",
    "    { \"title\": \"Histogram of Variables\"\n",
    "    , \"data\": initial_variables\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.0f}k'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.1f}k'\n",
    "    , \"xlabel\": \"Reducible Items\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Clauses\"\n",
    "    , \"data\": bybench.clauses\n",
    "    , \"xformat\" : lambda x, pos: f'{x / 1000 :0.0f}k'\n",
    "    , \"format\" : lambda x, pos: f'{x / 1000 :0.1f}k'\n",
    "    , \"xlabel\": \"Clauses\"\n",
    "    },\n",
    "    { \"title\": \"Histogram of Procentage\"\n",
    "    , \"data\": bybench.graphscore\n",
    "    , \"xformat\" : lambda x, pos: f'{x * 100 :0.0f}%'\n",
    "    , \"format\" : lambda x, pos: f'{x * 100 :0.1f}%'\n",
    "    , \"xlabel\": \"Edges per Clause\"\n",
    "    , \"splits\": np.linspace(bybench.graphscore.min(), 1, 11)\n",
    "    },\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "axes[0][0].set_ylabel(\"Bencmarks\")\n",
    "axes[1][0].set_ylabel(\"Bencmarks\")\n",
    "for ax, diagram in zip(axes.flatten(), diagrams):\n",
    "    pretty(ax)\n",
    "    \n",
    "    data = diagram[\"data\"]\n",
    "    xlim = (data.min(), data.max())\n",
    "    splits = diagram.get(\"splits\",np.linspace(*xlim, 11).round(0))\n",
    "    \n",
    "    \n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xticks(splits[::2])\n",
    "    ax.set_xticks(splits, minor=True)\n",
    "    \n",
    "    \n",
    "    ylim = (0, number_of_benchmarks)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yticks(np.linspace(*ylim, 8).round(0))\n",
    "    if not ax in (axes[0][0], axes[1][0]):\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        for x in ax.yaxis.get_major_ticks():\n",
    "            x.set_visible(False)\n",
    "    ax.set_xlabel(diagram[\"xlabel\"])\n",
    "   \n",
    "    blocks = ax.hist(diagram[\"data\"], splits, color=\"black\", rwidth=0.75)\n",
    "    \n",
    "    \n",
    "    xformat = diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(xformat))\n",
    "    #ax.xaxis.set_tick_params(rotation=70)\n",
    "    \n",
    "    gmean = stats.gmean(diagram[\"data\"])\n",
    "    v = ax.vlines(gmean, *ylim)\n",
    "    v.set_color(\"gray\")\n",
    "    v.set_linestyle(\":\")\n",
    "    \n",
    "    t = ax.text(gmean + (xlim[1] - xlim[0]) * 0.05, ylim[1] * 0.94, \"GM \" + diagram.get(\"format\", xformat)(gmean, 0))\n",
    "    t.set_color(\"gray\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.18)\n",
    "fig.savefig(\"figures/benchmarks.eps\")\n",
    "fig.savefig(\"figures/benchmarks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are testing four startegies: \n",
    "\n",
    "- `classes` which is equivilent to `jreduce`\n",
    "- `items+graph+first`\n",
    "- `items+graph+last`\n",
    "- `logic`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = list(reversed([\"classes\", \"items+logic\", \"items+graph+first\", \"items+graph+last\"]))\n",
    "\n",
    "p = [\"#0a1058\", \"#ee4242\", \"#ff9135\", \"#9857ff\", \"#4cb2ff\"]\n",
    "\n",
    "\n",
    "colors = { \"classes\" : \"#f38989\",  \"items+logic\": \"#cc2424\", \"items+graph+first\": \"#ff9135\", \"items+graph+last\": \"#ff9135\" }\n",
    "shade  = { \"classes\" : \"#F6F1B0\",  \"items+logic\": \"#B0B6F6\"}\n",
    "labels = { \"classes\" : \"J-Reduce\", \"items+logic\": \"Our Reducer\", \"items+graph+first\": \"Graph (First)\", \"items+graph+last\": \"Graph (Last)\"}\n",
    "styles = { \"classes\" : \"--\",       \"items+logic\": \"-\", \"items+graph+first\": \":\", \"items+graph+last\": \":\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  How many procent do each strategy time out on? (Answer NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10,0.7))\n",
    "\n",
    "timeouts = (results.status == \"timeout\").groupby(\"strategy\").mean()\n",
    "\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "pretty(ax)\n",
    "x = ax.barh(\n",
    "        [labels[s] + \" \" + str((100 - timeouts[s] * 100).round(1)) + \"%\" for s in strategies], \n",
    "        [timeouts[s] * 100 for s in strategies], \n",
    "        color=[colors[s] for s in strategies],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many benchmarks do 'classes' produce fewer classes than 'logic', and how many of them \n",
    "  are not due to timeouts? Answer NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outperforms = []\n",
    "for (b, p, x) in results.index:\n",
    "    if x != \"classes\": continue\n",
    "    c = results.classes\n",
    "    if c.loc[(b, p, x)] < c.loc[(b, p, \"items+logic\")]:\n",
    "        outperforms.append(\n",
    "            ( b + \"/\" + p\n",
    "            , (c.loc[(b, p, \"items+logic\")] / c.loc[(b, p, \"classes\")]).round(1)\n",
    "            , results.loc[(b,p,\"items+logic\")].status\n",
    "            )\n",
    "        )\n",
    "len(outperforms), len([x for x in outperforms if x[2] != \"timeout\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ## Comparative reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first experiment we are going to look at comparative final size, and time. We use the geometric mean, so that we can compare the results. We supress some warnings because when using the \"time\" column name pandas have a weird bug. Also we replace all 0's with 1's so that the gmean does not crash on the number of lines in the 'jreduce' output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Supressing warnings due to a bug in pandas\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    gmean = results[[\"time\", \"bytes\", \"classes\", \"lines\"]].replace(0, 1).groupby(\"strategy\").agg(stats.gmean)\n",
    "\n",
    "gmean.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also include the mediean for completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[[\"time\", \"bytes\", \"classes\", \"lines\"]].groupby(\"strategy\").median().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `classes` as a replacement of `jreduce` in the rest of the evaluation, so we want to make sure that they are equvilent on the two parameteres we can meassure on: \"time\" and \"classes\". And we can see that it is within a single percent in number of classes and 4% in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((gmean.loc[\"classes\"] / gmean.loc[\"jreduce\"]).loc[[\"time\", \"classes\"]] * 100) - 100).round(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On page 11 we compare J-Reduce with our new reducerers. To get the relative reduction we need the initial bytes, classes, and lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Supressing warnings due to a bug in pandas\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    initial = results[[\"initial-bytes\", \"initial-classes\", \"initial-lines\"]]\\\n",
    "     .replace(0, 1)\\\n",
    "     .groupby(\"strategy\").agg(stats.gmean)\\\n",
    "     .rename(lambda n: n[8:], axis=1)\n",
    "initial.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the results, as presented in the paper, where we use that J-Reduce is the `classses` strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = (gmean[[\"bytes\", \"classes\", \"lines\"]] / initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claims of Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(x): return (x * 100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tool reduces Java Bytecode to 4.6% of the size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent(rel[\"bytes\"][\"items+logic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is 5.3 times better than 24.3% achived by J-Reduce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent(rel[\"bytes\"][\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rel[\"bytes\"][\"classes\"] / rel[\"bytes\"][\"items+logic\"]).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does this by only being 3.1 times slower. **(In this dataset it becomes 3.3)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gmean[\"time\"][\"items+logic\"] / gmean[\"time\"][\"classes\"]).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the same amount of reduction produces by J-Reduce we can achive that with our reducer after only 6 minutes: See figure 8 (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that J-Reduce's and our reducers geometric mean running time is 218.6 s and 680.7 s respectively. **(In this dataset it becomes 220.0 s and 723.3 s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmean[\"time\"][[\"classes\", \"items+logic\"]].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduction of our reducer is much better: for number of classes we can reduce to 8.4 % while J-Reduce gets 22.8%, and for bytes we reduce to 4.6% while J-Reduce gets 24.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent(rel[[\"classes\", \"bytes\"]].loc[[\"classes\", \"items+logic\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform 2.7 times better on classes and 5.3 times better on bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rel.loc[\"classes\"] / rel.loc[\"items+logic\"])[[\"classes\", \"bytes\"]].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn our focus on the lossy encodings... \\[T\\]he first lossy encoding leads to a reduction 4% faster han our reduce while the \\[last\\] leads to a reduction that is 2% slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = gmean[\"time\"]\n",
    "percent(time[[\"items+graph+first\", \"items+graph+last\"]] / time[\"items+logic\"] -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first lossy encodeing produces 5% more bytes, \\[... last\\] produces 8% more bytes. Similarly, \\[.. 6% and 8%\\] more lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent(gmean.loc[[\"items+graph+first\", \"items+graph+last\"]] / gmean.loc[\"items+logic\"] - 1)[[\"bytes\", \"lines\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall our reducer is better than the first lossy encoding for 94% of the benchmarks \\[... \\] the second lossy encoding for 96% of our benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onbytes = results.unstack(\"strategy\")[\"bytes\"]\n",
    "print(\"items+graph+first\", \n",
    " percent((onbytes[\"items+graph+first\"] >= onbytes[\"items+logic\"]).mean()))\n",
    "print(\"items+graph+last\", \n",
    " percent((onbytes[\"items+graph+last\"] >= onbytes[\"items+logic\"]).mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8 (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Cumulative Frequencey Diagrams listed in Figure 8 (a), including the final size in lines as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_diagram(full):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12,3.2), sharey=True)\n",
    "    \n",
    "    diagrams = [\n",
    "        { \"title\": \"Finished Programs over Time\"\n",
    "        , \"xformat\": lambda x, pos: f'{x/3600:0.0f}:{x%3600/60:02.0f}'\n",
    "        , \"labelformat\": lambda x: f'{x:0.1f}s'\n",
    "        , \"data\": lambda s: list(sorted(d for d in full[\"time\"].unstack(\"strategy\")[s]))\n",
    "        , \"xlim\": (0, 10 * 3600)\n",
    "        , \"xticks\": np.linspace(0, 10*3600, 6)\n",
    "        , \"xlabel\": \"Time Spent (h:mm)\"\n",
    "        , \"percent\": False\n",
    "        },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"labelformat\": lambda x: f'{x*100:0.1f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"classes\"].unstack(\"strategy\")[s] / initial_classes)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Classes)\"\n",
    "        },\n",
    "        # { \"title\": \"Finished Programs over Invocations\"\n",
    "        # , \"xformat\": lambda x, pos: f'{x:0.0f}'\n",
    "        # , \"data\": lambda s: sorted(full[\"iters\"].unstack(\"strategy\")[s])\n",
    "        # , \"xlim\": (0, full[\"iters\"].max())\n",
    "        # , \"xlabel\": \"Invocations Made\"\n",
    "        # },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"labelformat\": lambda x: f'{x*100:0.1f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"bytes\"].unstack(\"strategy\")[s] / initial_bytes)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Bytes)\"\n",
    "        },\n",
    "        { \"title\": \"Finished Programs over Invocations\"\n",
    "        , \"xformat\": lambda x, pos: f'{x*100:0.0f}%'\n",
    "        , \"labelformat\": lambda x: f'{x*100:0.1f}%'\n",
    "        , \"data\": lambda s: sorted(full[\"lines\"].unstack(\"strategy\")[s] / initial_lines)\n",
    "        , \"xticks\": np.linspace(0,1, 6)\n",
    "        , \"xlabel\": \"Final Relative Size (Lines)\"\n",
    "        },\n",
    "        \n",
    "        ]\n",
    "\n",
    "    for diagram, ax in zip(diagrams, axes.flatten()):\n",
    "        maxx, minx = 0, 1000000000\n",
    "        pretty(ax)\n",
    "       \n",
    "        strats = sorted([\"classes\", \"items+logic\"], key=lambda s: np.mean(diagram[\"data\"](s)))\n",
    "        for s in strats:\n",
    "            data = diagram[\"data\"](s)\n",
    "            ax.plot(data, [i + 1 for i,_ in enumerate(data)], \n",
    "                    label=labels[s], \n",
    "                    linestyle=styles[s],\n",
    "                    color=colors[s])\n",
    "            maxx = max(maxx, max(data))\n",
    "            minx = min(minx, min(data))\n",
    "            \n",
    "            mean = stats.gmean(data)\n",
    "            for i, x in enumerate(data):\n",
    "                if x > mean: \n",
    "                    index = i + 1\n",
    "                    break\n",
    "            \n",
    "            ax.scatter(mean, index, color=colors[s])\n",
    "            if s == \"items+logic\":\n",
    "                loc = (mean + 6 / 100 * diagram[\"xticks\"][-1], index * 1.05 - 2)\n",
    "            else:\n",
    "                loc = (mean + 4 / 100 * diagram[\"xticks\"][-1] , index - 18)\n",
    "            \n",
    "            ax.text(*loc, diagram[\"labelformat\"](mean)\n",
    "                    , color=colors[s]\n",
    "                    , bbox=dict(boxstyle=\"round\", fc=\"white\", ec=\"white\")\n",
    "                   )\n",
    "            \n",
    "        minx = max(1, minx)\n",
    "        \n",
    "\n",
    "        xlim = diagram.get(\"xlim\", (0, maxx))\n",
    "        ax.set_xlim(*xlim)\n",
    "        xtics = diagram.get(\"xticks\", np.linspace(*xlim, 7))\n",
    "        ax.set_xticks(xtics)\n",
    "        \n",
    "        ylim = 0, number_of_benchmarks\n",
    "        ax.set_yticks(np.linspace(*ylim, 7).round())\n",
    "        ax.set_yticks([], minor=True)\n",
    "        ax.set_ylim(*ylim)\n",
    "        if ax == axes[0]:\n",
    "            ax.set_ylabel(\"Benchmarks\")\n",
    "        \n",
    "        \n",
    "        if diagram.get(\"percent\", False):\n",
    "            ax2 = ax.twinx()\n",
    "            pretty(ax2)\n",
    "            \n",
    "            yticks = [227, 200]\n",
    "            strats = sorted(strategies, key=lambda s: -len(diagram[\"data\"](s)))\n",
    "            ytickslabels = [f\"{(len(diagram['data'](s)) - 1) / number_of_benchmarks * 100:0.0f} %\" for s in strats]\n",
    "            ax2.set_yticks(yticks)\n",
    "            ax2.set_yticklabels(ytickslabels)\n",
    "        \n",
    "        \n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(diagram.get(\"xformat\", lambda x, pos: f'{x:0.0f}')))\n",
    "        \n",
    "        \n",
    "        v = ax.hlines(round(number_of_benchmarks/2),*xlim)\n",
    "        v.set_color(\"gray\")\n",
    "        v.set_linestyle(\":\")\n",
    "                                      \n",
    "        if ax == axes[0]:\n",
    "            t = axes[0].text(15005, round(len(data)/2) + 4.5, \"MEDIAN\")\n",
    "            t.set_color(\"gray\")\n",
    "                            \n",
    "            \n",
    "        \n",
    "        ax.set_xlabel(diagram[\"xlabel\"])    \n",
    "    \n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.13)\n",
    "    axes[2].legend(loc=\"lower right\")\n",
    "    return fig\n",
    "\n",
    "fig = draw_diagram(results)\n",
    "fig.savefig(\"figures/timings.eps\")\n",
    "fig.savefig(\"figures/timings.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8 (b) \n",
    "\n",
    "Figure 8 (b) is using the `bytes.csv` and `classes.csv` files which contains the number of bytes left after some amount of time. The extraction code can be found in `bin/minutes.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Supressing warnings due to a bug in pandas\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    tbytes = pd.read_csv(folder / \"bytes.csv\").groupby(\"strategy\").agg(stats.gmean).T.rename(int)\n",
    "    tclasses = pd.read_csv(folder / \"classes.csv\").groupby(\"strategy\").agg(stats.gmean).T.rename(int)\n",
    "\n",
    "    fclasses = results.classes.groupby(\"strategy\").agg(stats.gmean)\n",
    "    fbytes = results.bytes.groupby(\"strategy\").agg(stats.gmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10,5.6))\n",
    "\n",
    "diagrams = [\n",
    "    { \"title\": \"Mean Classes Left Over Time\"\n",
    "    , \"data\":  tclasses\n",
    "    , \"format\": lambda x, pos: f\"{x:0.0f}\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Mean Classes Left\"\n",
    "    , \"best\": fclasses\n",
    "    },\n",
    "    { \"title\": \"Mean Bytes Left Over Time (h:m)\"\n",
    "    , \"data\":  tbytes\n",
    "    , \"format\": lambda x, pos: f\"{x / 1000:0.0f} KB\"\n",
    "    , \"percent\": True\n",
    "    , \"ylabel\": \"Mean Bytes Left\"\n",
    "    , \"best\": fbytes\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Classes Over Time\"\n",
    "    , \"data\":  tclasses.rdiv(tclasses.max())\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylim\": (1, 25)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 25, 7)\n",
    "    , \"ylabel\": \"Mean Times Smaller (Classes)\"\n",
    "    , \"xlabel\": \"Time Spent (h:mm)\"\n",
    "    , \"percent\": False\n",
    "    , \"best\": fclasses.rdiv(tclasses.max())\n",
    "    },\n",
    "    { \"title\": \"Mean Reduction of Bytes Over Time\"\n",
    "    , \"data\":  tbytes.rdiv(tbytes.max())\n",
    "    , \"ylim\": (1, 25)\n",
    "    , \"yscale\": \"linear\"\n",
    "    , \"yticks\": np.linspace(1, 25, 7)\n",
    "    , \"format\": lambda x, pos: f\"x {x:0.0f}\"\n",
    "    , \"ylabel\": \"Mean Times Smaller (Bytes)\"\n",
    "    , \"percent\": False\n",
    "    , \"xlabel\": \"Time Spent (h:mm)\"\n",
    "    , \"best\": fbytes.rdiv(tbytes.max())\n",
    "    }\n",
    "]\n",
    "\n",
    "for ax, diagram in zip(axes.flatten(), diagrams):\n",
    "    data = diagram[\"data\"]\n",
    "   \n",
    "    pretty(ax)\n",
    "    strats = [\"classes\", \"items+logic\"]    \n",
    "    for s in reversed(strats):\n",
    "        ax.plot(data.index * 60, data[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "        \n",
    "        v = ax.hlines(diagram[\"best\"][s],(data.index * 60).min(), (data.index * 60).max())\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    "        \n",
    "        quantiles = diagram.get(\"quantiles\", None)\n",
    "        if quantiles:\n",
    "            low,high = quantiles\n",
    "            ax.fill_between(low.index * 60, low[s], high[s], label=labels[s], color=shade[s], linestyle=styles[s])\n",
    "            #ax.plot(high.index * 60, high[s], label=labels[s], color=colors[s], linestyle=styles[s])\n",
    "            \n",
    "        \n",
    "    ylim = diagram.get(\"ylim\", (0, data[strats].max().max()))\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "    yticks = diagram.get(\"yticks\", np.linspace(*ylim, 6).round())\n",
    "    ax.set_yticks([],minor=True)\n",
    "    ax.set_yticks(yticks)\n",
    "    yformat = diagram[\"format\"]\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(yformat))\n",
    "    \n",
    "    ax.set_ylabel(diagram.get(\"ylabel\"))\n",
    "    \n",
    "    xlabel = diagram.get(\"xlabel\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    \n",
    "    v = ax.vlines(6*60, *ylim)\n",
    "    v.set_color(\"lightgray\")\n",
    "    v.set_linestyle(\":\")\n",
    "    \n",
    "    t = ax.text(8*60, 25 if ylim[1] == 25 else ylim[1] * 0.95, \"0:06\")\n",
    "    t.set_color(\"gray\")\n",
    "  \n",
    "    \n",
    "    if diagram.get(\"percent\", False):\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.yaxis.set_major_formatter(matplotlib.ticker.PercentFormatter(1, 0))\n",
    "    else: \n",
    "        ax2 = ax.twinx()\n",
    "        pretty(ax2)\n",
    "        ax2.spines['right'].set_visible(True)\n",
    "        ax2.set_ylabel(\"Percentage Left\")\n",
    "        ax2.set_ylim(*ylim)\n",
    "        ax2.set_yscale(diagram.get(\"yscale\", \"linear\"))\n",
    "        \n",
    "        onehour = (diagram[\"data\"][\"items+logic\"].loc[60])\n",
    "        \n",
    "        v = ax.hlines(onehour,(data.index * 60).min(), (data.index * 60).max())\n",
    "        v.set_color(\"lightgray\")\n",
    "        v.set_linestyle(\":\")\n",
    " \n",
    "        \n",
    "        yticks, ytickslabels = zip(\n",
    "            *diagram.get(\"yticks2\",\n",
    "                        [ (d, f\"{1/d * 100:0.1f}%\") for d in (diagram[\"best\"][s] for s in strats)\n",
    "                        ] + [(onehour, f\"{1/onehour * 100:0.1f}%\")]\n",
    "            ))\n",
    "        ax2.set_yticks(yticks)\n",
    "        ax2.set_yticklabels(ytickslabels)\n",
    "        ax2.set_yticks([],minor=True)\n",
    "        \n",
    "        ax2.invert_yaxis()\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "    xlim = (0, 60 * 60 * 2 + 1)\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_xticks(np.linspace(*xlim, 5))\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, pos: f'{math.floor(x/3600):0.0f}:{x%3600/60:02.0f}'))\n",
    "    \n",
    "   \n",
    "axes[0][0].legend()\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.20)\n",
    "fig.savefig(\"figures/by-time.eps\")\n",
    "fig.savefig(\"figures/by-time.png\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of example\n",
    "\n",
    "We choose an example in the introduction, we choose it as close to the mean of the difference between J-Reduce and our reducer, while still being as close to the geometric mean as possible.\n",
    "\n",
    "In the example below, we both list the number of lines in the median (113) and the example we choose (129), we also list the times our approach is better in number of bytes left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results.unstack(\"strategy\")\n",
    "b = x[\"bytes\"]\n",
    "index = (b[\"classes\"] / b[\"items+logic\"]).sort_values().index[[113,129]]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"initial\": x[\"initial-lines\"][\"classes\"],\n",
    "    \"classes\": x[\"lines\"][\"classes\"],\n",
    "    \"items+logic\": x[\"lines\"][\"items+logic\"],\n",
    "    \"better\": (b[\"classes\"] / b[\"items+logic\"]).round(1)\n",
    "}).loc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Evaluation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((results[\"time\"].sum() / 3600).round(), \"h\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
